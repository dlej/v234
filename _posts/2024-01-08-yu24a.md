---
title: Emergence of Segmentation with Minimalistic White-Box Transformers
openreview: kmzH8kT9TE
abstract: Transformer-like models for vision tasks have recently proven effective
  for a wide range of downstream applications such as segmentation and detection.  Previous
  works have shown that segmentation properties emerge in vision transformers (ViTs)
  trained using self-supervised methods such as DINO, but not in those trained on
  supervised classification tasks.  In this study, we probe whether segmentation emerges
  in transformer-based models solely as a result of intricate self-supervised learning
  mechanisms, or if the same emergence can be achieved under much broader conditions
  through proper design of the model architecture.  Through extensive experimental
  results, we demonstrate that when employing a white-box transformer-like architecture
  known as CRATE, whose design explicitly models and pursues low-dimensional structures
  in the data distribution, segmentation properties, at both the whole and parts levels,
  already emerge with a minimalistic supervised training recipe.  Layer-wise finer-grained
  analysis reveals that the emergent properties strongly corroborate the designed
  mathematical functions of the white-box network. Our results suggest a path to design
  white-box foundation models that are simultaneously highly performant and mathematically
  fully interpretable.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yu24a
month: 0
tex_title: Emergence of Segmentation with Minimalistic White-Box Transformers
firstpage: 72
lastpage: 93
page: 72-93
order: 72
cycles: false
bibtex_author: Yu, Yaodong and Chu, Tianzhe and Tong, Shengbang and Wu, Ziyang and
  Pai, Druv and Buchanan, Sam and Ma, Yi
author:
- given: Yaodong
  family: Yu
- given: Tianzhe
  family: Chu
- given: Shengbang
  family: Tong
- given: Ziyang
  family: Wu
- given: Druv
  family: Pai
- given: Sam
  family: Buchanan
- given: Yi
  family: Ma
date: 2024-01-08
address:
container-title: Conference on Parsimony and Learning
volume: '234'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 8
pdf: https://proceedings.mlr.press/v234/yu24a/yu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
