---
title: Exploring Minimally Sufficient Representation in Active Learning through Label-Irrelevant
  Patch Augmentation
openreview: MlgnGWdqWl
abstract: 'Deep learning models, which require abundant labeled data for training,
  are expensive and time-consuming to implement, particularly in medical imaging.
  Active learning (AL) aims to maximize model performance with few labeled samples
  by gradually expanding and labeling a new training set. In this work, we intend
  to learn a "good" feature representation that is both sufficient and minimal, facilitating
  effective AL for medical image classification. This work proposes an efficient AL
  framework based on off-the-shelf self-supervised learning models, complemented by
  a label-irrelevant patch augmentation scheme. This scheme is designed to reduce
  redundancy in the learned features and mitigate overfitting in the progress of AL.
  Our framework offers efficiency to AL in terms of parameters, samples, and computational
  costs. The benefits of this approach are extensively validated across various medical
  image classification tasks employing different AL strategies.Â \footnote{Source Codes:
  \url{https://github.com/chrisyxue/DA4AL}}.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xue24a
month: 0
tex_title: Exploring Minimally Sufficient Representation in Active Learning through
  Label-Irrelevant Patch Augmentation
firstpage: 419
lastpage: 439
page: 419-439
order: 419
cycles: false
bibtex_author: Xue, Zhiyu and Dai, Yinlong and Lei, Qi
author:
- given: Zhiyu
  family: Xue
- given: Yinlong
  family: Dai
- given: Qi
  family: Lei
date: 2024-01-08
address:
container-title: Conference on Parsimony and Learning
volume: '234'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 8
pdf: https://proceedings.mlr.press/v234/xue24a/xue24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
