---
title: Domain Generalization via Nuclear Norm Regularization
openreview: hJd66ZzXEZ
abstract: The ability to generalize to unseen domains is crucial for machine learning
  systems deployed in the real world, especially when we only have data from limited
  training domains. In this paper, we propose a simple and effective regularization
  method based on the nuclear norm of the learned features for domain generalization.
  Intuitively, the proposed regularizer mitigates the impacts of environmental features
  and encourages learning domain-invariant features. Theoretically, we provide insights
  into why nuclear norm regularization is more effective compared to ERM and alternative
  regularization methods. Empirically, we conduct extensive experiments on both synthetic
  and real datasets. We show nuclear norm regularization achieves strong performance
  compared to baselines in a wide range of domain generalization tasks. Moreover,
  our regularizer is broadly applicable with various methods such as ERM and SWAD
  with consistently improved performance, e.g., 1.7% and 0.9%  test accuracy improvements
  respectively on the DomainBed benchmark.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shi24a
month: 0
tex_title: Domain Generalization via Nuclear Norm Regularization
firstpage: 179
lastpage: 201
page: 179-201
order: 179
cycles: false
bibtex_author: Shi, Zhenmei and Ming, Yifei and Fan, Ying and Sala, Frederic and Liang,
  Yingyu
author:
- given: Zhenmei
  family: Shi
- given: Yifei
  family: Ming
- given: Ying
  family: Fan
- given: Frederic
  family: Sala
- given: Yingyu
  family: Liang
date: 2024-01-08
address:
container-title: Conference on Parsimony and Learning
volume: '234'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 8
pdf: https://proceedings.mlr.press/v234/shi24a/shi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
